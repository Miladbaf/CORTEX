{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbe52824",
   "metadata": {},
   "source": [
    "# CORTEX â€” Stage II: Discrete Beam Selection\n",
    "\n",
    "> **Focal Loss Â· Knowledge Distillation Â· Causal Transformer Â· Angle Refinement Â· IEEE Paper Plots**\n",
    "\n",
    "This notebook trains **CORTEX Stage II**, which selects optimal TX/RX beam patterns (from a 255Ã—255 codebook) for THz UAV communications.  \n",
    "It operates on raw mobility traces, runs an exhaustive search teacher to generate soft labels, and trains a causal transformer student with knowledge distillation.\n",
    "\n",
    "### Architecture\n",
    "```\n",
    "Input state sequence  [B, T, F=17]\n",
    "      â”‚\n",
    "      â–¼\n",
    "Conv Front-End    (2Ã— Conv1d + GELU)\n",
    "      â”‚\n",
    "      â–¼\n",
    "Causal Transformer   (NÃ— RoPE self-attention + FFN)   â†’ context encoding\n",
    "      â”‚\n",
    "   last token + mean pool â†’ query\n",
    "      â”‚\n",
    "      â”œâ”€â†’ Cross-attention over TX beam codebook â†’ TX classifier  (255-way)\n",
    "      â”œâ”€â†’ Cross-attention over RX beam codebook â†’ RX classifier  (255-way)\n",
    "      â””â”€â†’ Angle Refiner MLP                    â†’ 6-D unit vector (TX + RX)\n",
    "```\n",
    "\n",
    "**Training signal**: Focal loss on hard labels + KL-divergence distillation from exhaustive-search teacher (top-K soft targets, temperature-annealed).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4db481",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch numpy matplotlib pandas scipy scikit-learn einops -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a324024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "import time, os, glob, math, json\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa36ae7f",
   "metadata": {},
   "source": [
    "## 1 Â· Setup: Output Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15359946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Option A: Google Colab + Drive â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\", force_remount=False)\n",
    "    EXPERIMENT_ROOT = \"/content/drive/MyDrive/CORTEX_experiments_255\"\n",
    "    print(\"âœ… Google Drive mounted\")\n",
    "except ImportError:\n",
    "    # â”€â”€ Option B: Local â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    EXPERIMENT_ROOT = \"outputs\"\n",
    "    print(\"â„¹ï¸  Running locally â€” outputs go to ./outputs/\")\n",
    "\n",
    "CHECKPOINT_DIR = os.path.join(EXPERIMENT_ROOT, \"checkpoints\")\n",
    "DATA_CACHE_DIR = os.path.join(EXPERIMENT_ROOT, \"data_cache\")\n",
    "RESULTS_DIR    = os.path.join(EXPERIMENT_ROOT, \"results\")\n",
    "LOGS_DIR       = os.path.join(EXPERIMENT_ROOT, \"logs\")\n",
    "\n",
    "for d in [CHECKPOINT_DIR, DATA_CACHE_DIR, RESULTS_DIR, LOGS_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print(f\"Checkpoints : {CHECKPOINT_DIR}\")\n",
    "print(f\"Data cache  : {DATA_CACHE_DIR}\")\n",
    "print(f\"Results     : {RESULTS_DIR}\")\n",
    "print(f\"Logs        : {LOGS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603fa589",
   "metadata": {},
   "source": [
    "## 2 Â· Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f3fcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # â”€â”€ Beam codebook â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    NUM_TX_PATTERNS = 255\n",
    "    NUM_RX_PATTERNS = 255\n",
    "\n",
    "    # â”€â”€ THz channel â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    FREQUENCY  = 272.5e9\n",
    "    BANDWIDTH  = 14e9\n",
    "    C          = 3e8\n",
    "    KB         = 1.380649e-23\n",
    "    T0         = 296\n",
    "    T_SYS      = 1000\n",
    "    P_TX       = 0.1\n",
    "\n",
    "    # â”€â”€ Input / sequence â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    STATE_FEATURE_DIM = 17\n",
    "    SEQUENCE_LENGTH   = 7\n",
    "\n",
    "    # â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    D_MODEL        = 256\n",
    "    N_HEADS        = 8\n",
    "    N_LAYERS       = 5\n",
    "    DIM_FEEDFORWARD= 512\n",
    "    DROPOUT        = 0.15\n",
    "    BEAM_EMBED_DIM = 128\n",
    "    CONV_CHANNELS  = 128\n",
    "    CONV_KERNEL    = 5\n",
    "    CONV_STRIDE    = 2\n",
    "    CONV_LAYERS    = 2\n",
    "\n",
    "    # â”€â”€ Training â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    LEARNING_RATE = 2e-4\n",
    "    BATCH_SIZE    = 16\n",
    "    NUM_EPOCHS    = 250\n",
    "    TRAIN_SPLIT   = 0.8\n",
    "\n",
    "    # â”€â”€ Knowledge distillation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    USE_DISTILLATION        = True\n",
    "    DISTILL_TEMPERATURE_MAX = 8.0\n",
    "    DISTILL_TEMPERATURE_MIN = 3.0\n",
    "    DISTILL_ALPHA_MIN       = 0.2\n",
    "    DISTILL_ALPHA_MAX       = 0.6\n",
    "    TOPK_TX                 = 6\n",
    "    TOPK_RX                 = 6\n",
    "\n",
    "    # â”€â”€ Losses â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    FOCAL_GAMMA     = 2.0\n",
    "    LABEL_SMOOTHING = 0.1\n",
    "\n",
    "    # â”€â”€ Angle refinement â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    USE_ANGLE_REFINEMENT = True\n",
    "    ANGLE_LOSS_WEIGHT    = 0.20\n",
    "    WC_RHO               = 0.9\n",
    "\n",
    "    # â”€â”€ Checkpointing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    CHECKPOINT_EVERY_N_EPOCHS  = 10\n",
    "    KEEP_LAST_N_CHECKPOINTS    = 5\n",
    "    DATA_GEN_CHECKPOINT_EVERY  = 50\n",
    "\n",
    "config = Config()\n",
    "print(\"Config ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23796bc9",
   "metadata": {},
   "source": [
    "## 3 Â· Load Radiation Patterns & Mobility Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a00a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Set paths â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Update these to point to your data locations.\n",
    "PATTERNS_DIR   = \"data/255_dataset\"        # folder of rows_*.csv antenna patterns\n",
    "MOBILITY_FILE  = \"data/mobility.csv\"       # mobility trace CSV\n",
    "\n",
    "# Auto-detect Drive locations if running on Colab\n",
    "if not os.path.exists(PATTERNS_DIR):\n",
    "    for candidate in [\n",
    "        \"/content/drive/MyDrive/2D Radiation Patterns/255_dataset\",\n",
    "        \"/content/drive/My Drive/2D Radiation Patterns/255_dataset\",\n",
    "    ]:\n",
    "        if os.path.exists(candidate):\n",
    "            PATTERNS_DIR = candidate\n",
    "            print(f\"Auto-detected patterns: {PATTERNS_DIR}\")\n",
    "            break\n",
    "\n",
    "if not os.path.exists(MOBILITY_FILE):\n",
    "    for candidate in glob.glob(\"/content/drive/**/*.csv\", recursive=True):\n",
    "        if \"mobility\" in os.path.basename(candidate).lower():\n",
    "            MOBILITY_FILE = candidate\n",
    "            print(f\"Auto-detected mobility: {MOBILITY_FILE}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e7c931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hfss_patterns_from_csv(directory, glob_pattern=\"rows_*.csv\", expected_num=255):\n",
    "    \"\"\"Load 2-D antenna radiation patterns from CSV files.\"\"\"\n",
    "    print(f\"Loading {expected_num} radiation patterns from {directory}...\")\n",
    "    csv_files = sorted(glob.glob(os.path.join(directory, glob_pattern)))\n",
    "    patterns = {}\n",
    "\n",
    "    for pid, csv_file in enumerate(csv_files[:expected_num]):\n",
    "        df = pd.read_csv(csv_file)\n",
    "\n",
    "        phi_col   = next(c for c in df.columns if \"phi\"   in c.lower())\n",
    "        theta_col = next(c for c in df.columns if \"theta\" in c.lower())\n",
    "        gain_col  = next(c for c in df.columns if \"gain\"  in c.lower())\n",
    "\n",
    "        phi_deg   = pd.to_numeric(df[phi_col], errors=\"coerce\").values % 360\n",
    "        theta_deg = pd.to_numeric(\n",
    "            df[theta_col].astype(str).str.replace(\"deg\", \"\"), errors=\"coerce\"\n",
    "        ).values\n",
    "        gain_db   = pd.to_numeric(df[gain_col], errors=\"coerce\").values\n",
    "\n",
    "        phi_u   = np.sort(np.unique(phi_deg))\n",
    "        theta_u = np.sort(np.unique(theta_deg))\n",
    "        gain_2d = np.full((len(phi_u), len(theta_u)), -100.0)\n",
    "\n",
    "        for i in range(len(df)):\n",
    "            pi = np.argmin(np.abs(phi_u   - phi_deg[i]))\n",
    "            ti = np.argmin(np.abs(theta_u - theta_deg[i]))\n",
    "            gain_2d[pi, ti] = gain_db[i]\n",
    "\n",
    "        patterns[pid] = {\n",
    "            \"phi_angles\":   phi_u,\n",
    "            \"theta_angles\": theta_u,\n",
    "            \"gain_linear\":  10.0 ** (gain_2d / 10.0),\n",
    "        }\n",
    "        if (pid + 1) % 50 == 0:\n",
    "            print(f\"  {pid+1}/{expected_num}\")\n",
    "\n",
    "    print(f\"âœ… Loaded {len(patterns)} patterns\")\n",
    "    return patterns\n",
    "\n",
    "\n",
    "gain_database = load_hfss_patterns_from_csv(PATTERNS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984bb657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mobility_trace(filepath):\n",
    "    \"\"\"Load a single mobility trace CSV.\"\"\"\n",
    "    required = [\"time\", \"x_tx\", \"y_tx\", \"z_tx\", \"x_rx\", \"y_rx\", \"z_rx\",\n",
    "                \"vx_tx\", \"vy_tx\", \"vz_tx\", \"vx_rx\", \"vy_rx\", \"vz_rx\"]\n",
    "    df = pd.read_csv(filepath)\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns: {missing}\")\n",
    "    print(f\"âœ… Loaded mobility trace: {len(df)} timesteps \"\n",
    "          f\"({df['time'].min():.1f}s â€“ {df['time'].max():.1f}s)\")\n",
    "    return df\n",
    "\n",
    "\n",
    "mobility_trace = load_mobility_trace(MOBILITY_FILE)\n",
    "pattern_name   = Path(MOBILITY_FILE).stem   # used as key for caching/checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cec52e0",
   "metadata": {},
   "source": [
    "## 4 Â· THz Channel & Exhaustive-Search Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61398df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class THzChannel:\n",
    "    \"\"\"THz channel model: path loss + molecular absorption + thermal noise.\"\"\"\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "        self.f, self.B, self.c = cfg.FREQUENCY, cfg.BANDWIDTH, cfg.C\n",
    "        self.kB, self.T0, self.Tsys = cfg.KB, cfg.T0, cfg.T_SYS\n",
    "        self.K_abs = 0.05   # molecular absorption coefficient (mâ»Â¹)\n",
    "\n",
    "    def distance(self, xTx, yTx, zTx, xRx, yRx, zRx):\n",
    "        return np.sqrt((xRx-xTx)**2 + (yRx-yTx)**2 + (zRx-zTx)**2)\n",
    "\n",
    "    def angles(self, xTx, yTx, zTx, xRx, yRx, zRx):\n",
    "        dx, dy, dz = xRx-xTx, yRx-yTx, zRx-zTx\n",
    "        d = np.sqrt(dx**2 + dy**2 + dz**2) + 1e-10\n",
    "        phi_Tx   = np.degrees(np.arctan2(dy, dx)) % 360\n",
    "        theta_Tx = np.degrees(np.arccos(np.clip(dz/d, -1, 1)))\n",
    "        phi_Rx   = (phi_Tx + 180) % 360\n",
    "        theta_Rx = 180 - theta_Tx\n",
    "        return phi_Tx, theta_Tx, phi_Rx, theta_Rx\n",
    "\n",
    "    def channel_gain(self, d):\n",
    "        h_s  = self.c / (4 * np.pi * self.f * d)\n",
    "        tau  = np.exp(-self.K_abs * d)\n",
    "        return (h_s * np.sqrt(tau))**2, tau\n",
    "\n",
    "    def noise(self, tau):\n",
    "        return self.kB * (self.Tsys + self.T0 * (1 - tau)) * self.B\n",
    "\n",
    "    def capacity(self, GTx, GRx, ch_gain_sq, P_noise):\n",
    "        SNR = (config.P_TX * GTx * GRx * ch_gain_sq) / P_noise\n",
    "        return self.B * np.log2(1 + SNR), SNR\n",
    "\n",
    "\n",
    "channel = THzChannel(config)\n",
    "\n",
    "\n",
    "class ExhaustiveSearchTeacher:\n",
    "    \"\"\"\n",
    "    Brute-force beam selector (255Ã—255).\n",
    "    Provides hard labels AND per-beam capacity scores (soft targets).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cfg, gain_db, ch):\n",
    "        self.cfg = cfg\n",
    "        self.ch  = ch\n",
    "        self.interp = {}\n",
    "        for pid, pdata in gain_db.items():\n",
    "            self.interp[pid] = RegularGridInterpolator(\n",
    "                (pdata[\"phi_angles\"], pdata[\"theta_angles\"]),\n",
    "                pdata[\"gain_linear\"],\n",
    "                bounds_error=False, fill_value=None, method=\"linear\",\n",
    "            )\n",
    "\n",
    "    def gain(self, pid, phi, theta):\n",
    "        return max(self.interp[pid]([phi % 360, np.clip(theta, 0, 180)])[0], 1e-10)\n",
    "\n",
    "    def select(self, xTx, yTx, zTx, xRx, yRx, zRx):\n",
    "        \"\"\"Return (best_tx_idx, best_rx_idx, best_capacity).\"\"\"\n",
    "        d  = self.ch.distance(xTx, yTx, zTx, xRx, yRx, zRx)\n",
    "        ph_t, th_t, ph_r, th_r = self.ch.angles(xTx, yTx, zTx, xRx, yRx, zRx)\n",
    "        cg, tau = self.ch.channel_gain(d)\n",
    "        Pn = self.ch.noise(tau)\n",
    "\n",
    "        best_cap, best_tx, best_rx = -np.inf, 0, 0\n",
    "        for iTx in range(self.cfg.NUM_TX_PATTERNS):\n",
    "            for iRx in range(self.cfg.NUM_RX_PATTERNS):\n",
    "                cap, _ = self.ch.capacity(\n",
    "                    self.gain(iTx, ph_t, th_t),\n",
    "                    self.gain(iRx, ph_r, th_r), cg, Pn)\n",
    "                if cap > best_cap:\n",
    "                    best_cap, best_tx, best_rx = cap, iTx, iRx\n",
    "        return best_tx, best_rx, best_cap\n",
    "\n",
    "    def beam_scores(self, xTx, yTx, zTx, xRx, yRx, zRx):\n",
    "        \"\"\"Per-beam capacity scores for soft-target distillation.\"\"\"\n",
    "        d  = self.ch.distance(xTx, yTx, zTx, xRx, yRx, zRx)\n",
    "        ph_t, th_t, ph_r, th_r = self.ch.angles(xTx, yTx, zTx, xRx, yRx, zRx)\n",
    "        cg, tau = self.ch.channel_gain(d)\n",
    "        Pn = self.ch.noise(tau)\n",
    "        G0 = self.gain(0, ph_r, th_r)\n",
    "\n",
    "        tx_scores = np.array([\n",
    "            self.ch.capacity(self.gain(i, ph_t, th_t), G0, cg, Pn)[0]\n",
    "            for i in range(self.cfg.NUM_TX_PATTERNS)\n",
    "        ])\n",
    "        G0tx = self.gain(0, ph_t, th_t)\n",
    "        rx_scores = np.array([\n",
    "            self.ch.capacity(G0tx, self.gain(i, ph_r, th_r), cg, Pn)[0]\n",
    "            for i in range(self.cfg.NUM_RX_PATTERNS)\n",
    "        ])\n",
    "        return tx_scores, rx_scores\n",
    "\n",
    "\n",
    "teacher = ExhaustiveSearchTeacher(config, gain_database, channel)\n",
    "print(\"âœ… Channel and exhaustive-search teacher ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ab8456",
   "metadata": {},
   "source": [
    "## 5 Â· Checkpoint & Cache Managers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67714904",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheckpointManager:\n",
    "    \"\"\"Save / load model training checkpoints, keeping the last N.\"\"\"\n",
    "\n",
    "    def __init__(self, checkpoint_dir, pattern_name):\n",
    "        self.ckpt_dir = Path(checkpoint_dir)\n",
    "        self.ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.prefix = \"ckpt_\" + pattern_name.replace(\"/\", \"_\").replace(\" \", \"_\")[:100]\n",
    "\n",
    "    def save(self, epoch, model, optimizer, scheduler, metrics, is_best=False):\n",
    "        state = {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\":     model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "            \"metrics\":  metrics,\n",
    "            \"timestamp\": time.time(),\n",
    "        }\n",
    "        path = self.ckpt_dir / f\"{self.prefix}_epoch_{epoch:03d}.pth\"\n",
    "        torch.save(state, path)\n",
    "        torch.save(state, self.ckpt_dir / f\"{self.prefix}_latest.pth\")\n",
    "        if is_best:\n",
    "            torch.save(state, self.ckpt_dir / f\"{self.prefix}_best.pth\")\n",
    "            print(f\"  ðŸŒŸ Best checkpoint saved (epoch {epoch})\")\n",
    "\n",
    "        # Prune old checkpoints\n",
    "        ckpts = sorted(self.ckpt_dir.glob(f\"{self.prefix}_epoch_*.pth\"),\n",
    "                       key=lambda p: p.stat().st_mtime)\n",
    "        for old in ckpts[:-config.KEEP_LAST_N_CHECKPOINTS]:\n",
    "            old.unlink()\n",
    "\n",
    "    def load_latest(self):\n",
    "        path = self.ckpt_dir / f\"{self.prefix}_latest.pth\"\n",
    "        if path.exists():\n",
    "            return torch.load(path, map_location=device)\n",
    "        ckpts = sorted(self.ckpt_dir.glob(f\"{self.prefix}_epoch_*.pth\"),\n",
    "                       key=lambda p: p.stat().st_mtime)\n",
    "        if ckpts:\n",
    "            return torch.load(ckpts[-1], map_location=device)\n",
    "        return None\n",
    "\n",
    "    def load_best(self):\n",
    "        path = self.ckpt_dir / f\"{self.prefix}_best.pth\"\n",
    "        if path.exists():\n",
    "            return torch.load(path, map_location=device)\n",
    "        return None\n",
    "\n",
    "    def exists(self):\n",
    "        return (self.ckpt_dir / f\"{self.prefix}_latest.pth\").exists()\n",
    "\n",
    "\n",
    "class DataCacheManager:\n",
    "    \"\"\"Cache expensive exhaustive-search training data generation.\"\"\"\n",
    "\n",
    "    def __init__(self, cache_dir):\n",
    "        self.cache_dir = Path(cache_dir)\n",
    "        self.cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def _path(self, name, partial=False):\n",
    "        safe = name.replace(\"/\", \"_\").replace(\" \", \"_\")[:100]\n",
    "        suffix = \"_partial.npz\" if partial else \".npz\"\n",
    "        return self.cache_dir / f\"data_{safe}{suffix}\"\n",
    "\n",
    "    def save(self, name, sequences, labels_Tx, labels_Rx,\n",
    "             soft_tx, soft_rx, angle_vecs, partial_idx=None):\n",
    "        path = self._path(name, partial=partial_idx is not None)\n",
    "        kwargs = dict(sequences=np.array(sequences, dtype=np.float32),\n",
    "                      labels_Tx=np.array(labels_Tx),\n",
    "                      labels_Rx=np.array(labels_Rx),\n",
    "                      soft_tx=np.array(soft_tx,  dtype=np.float32),\n",
    "                      soft_rx=np.array(soft_rx,  dtype=np.float32),\n",
    "                      angle_vecs=np.array(angle_vecs, dtype=np.float32),\n",
    "                      timestamp=time.time())\n",
    "        if partial_idx is not None:\n",
    "            kwargs[\"last_idx\"] = partial_idx\n",
    "        np.savez_compressed(path, **kwargs)\n",
    "        if partial_idx is None:\n",
    "            # Remove partial file on successful completion\n",
    "            p = self._path(name, partial=True)\n",
    "            if p.exists(): p.unlink()\n",
    "\n",
    "    def load(self, name, partial=False):\n",
    "        path = self._path(name, partial=partial)\n",
    "        if not path.exists(): return None\n",
    "        d = np.load(path)\n",
    "        result = {k: d[k] for k in d.files}\n",
    "        if partial:\n",
    "            result[\"sequences\"]  = result[\"sequences\"].tolist()\n",
    "            result[\"labels_Tx\"]  = result[\"labels_Tx\"].tolist()\n",
    "            result[\"labels_Rx\"]  = result[\"labels_Rx\"].tolist()\n",
    "            result[\"soft_tx\"]    = result[\"soft_tx\"].tolist()\n",
    "            result[\"soft_rx\"]    = result[\"soft_rx\"].tolist()\n",
    "            result[\"angle_vecs\"] = result[\"angle_vecs\"].tolist()\n",
    "            result[\"last_idx\"]   = int(result[\"last_idx\"])\n",
    "        return result\n",
    "\n",
    "    def exists(self, name): return self._path(name).exists()\n",
    "    def partial_exists(self, name): return self._path(name, partial=True).exists()\n",
    "\n",
    "\n",
    "ckpt_manager  = CheckpointManager(CHECKPOINT_DIR, pattern_name)\n",
    "cache_manager = DataCacheManager(DATA_CACHE_DIR)\n",
    "print(\"âœ… Checkpoint and cache managers ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8cc181",
   "metadata": {},
   "source": [
    "## 6 Â· Angle Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8d0a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def angles_to_unit_vector(phi_Tx, theta_Tx, phi_Rx, theta_Rx):\n",
    "    \"\"\"Pack four angles (degrees) into a 6-D unit-vector array [tx(3) | rx(3)].\"\"\"\n",
    "    def sph2cart(phi_d, theta_d):\n",
    "        p, t = np.deg2rad(phi_d), np.deg2rad(theta_d)\n",
    "        return np.array([np.sin(t)*np.cos(p), np.sin(t)*np.sin(p), np.cos(t)])\n",
    "    return np.concatenate([sph2cart(phi_Tx, theta_Tx),\n",
    "                           sph2cart(phi_Rx, theta_Rx)]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6f02f0",
   "metadata": {},
   "source": [
    "## 7 Â· Training Data Generation (with Incremental Checkpointing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a501de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(trace, teacher, channel, seq_len,\n",
    "                            name, cache_mgr):\n",
    "    \"\"\"\n",
    "    Run exhaustive search over every timestep to produce:\n",
    "      - sequences     : [N, T, 17]  state feature windows\n",
    "      - labels_Tx/Rx  : [N]         hard beam indices\n",
    "      - soft_tx/rx    : [N, 255]    per-beam capacity scores (for KD)\n",
    "      - angle_vecs    : [N, 6]      unit vectors for angle-refinement loss\n",
    "\n",
    "    Results are cached to disk. Partial checkpoints are saved every\n",
    "    config.DATA_GEN_CHECKPOINT_EVERY samples so generation can resume\n",
    "    after an interruption.\n",
    "    \"\"\"\n",
    "    # â”€â”€ Try full cache â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    cached = cache_mgr.load(name)\n",
    "    if cached is not None:\n",
    "        print(\"âœ… Loaded data from cache\")\n",
    "        return (cached[\"sequences\"], cached[\"labels_Tx\"], cached[\"labels_Rx\"],\n",
    "                cached[\"soft_tx\"],   cached[\"soft_rx\"],   cached[\"angle_vecs\"])\n",
    "\n",
    "    # â”€â”€ Try partial checkpoint â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    partial = cache_mgr.load(name, partial=True)\n",
    "    if partial:\n",
    "        seqs, lTx, lRx = partial[\"sequences\"], partial[\"labels_Tx\"], partial[\"labels_Rx\"]\n",
    "        stx, srx, avecs = partial[\"soft_tx\"], partial[\"soft_rx\"], partial[\"angle_vecs\"]\n",
    "        start = partial[\"last_idx\"] + 1\n",
    "        print(f\"ðŸ”„ Resuming from index {start} ({len(seqs)} samples already done)\")\n",
    "    else:\n",
    "        seqs, lTx, lRx, stx, srx, avecs = [], [], [], [], [], []\n",
    "        start = seq_len - 1\n",
    "\n",
    "    total   = len(trace) - (seq_len - 1)\n",
    "    freq    = config.DATA_GEN_CHECKPOINT_EVERY\n",
    "    t_start = time.time()\n",
    "    since_ckpt = 0\n",
    "\n",
    "    print(f\"Generating {total} samples (checkpointing every {freq})â€¦\")\n",
    "\n",
    "    for idx in range(start, len(trace)):\n",
    "        # â”€â”€ Build feature window â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        window = []\n",
    "        for t in range(idx - seq_len + 1, idx + 1):\n",
    "            r = trace.iloc[t]\n",
    "            xT, yT, zT = r[\"x_tx\"], r[\"y_tx\"], r[\"z_tx\"]\n",
    "            xR, yR, zR = r[\"x_rx\"], r[\"y_rx\"], r[\"z_rx\"]\n",
    "            d   = channel.distance(xT, yT, zT, xR, yR, zR)\n",
    "            phT, thT, _, _ = channel.angles(xT, yT, zT, xR, yR, zR)\n",
    "            window.append([\n",
    "                xT/100, yT/100, zT/100, xR/100, yR/100, zR/100, d/100,\n",
    "                r[\"vx_tx\"]/10, r[\"vy_tx\"]/10, r[\"vz_tx\"]/10,\n",
    "                r[\"vx_rx\"]/10, r[\"vy_rx\"]/10, r[\"vz_rx\"]/10,\n",
    "                np.sin(np.deg2rad(phT)), np.cos(np.deg2rad(phT)),\n",
    "                np.sin(np.deg2rad(thT)), np.cos(np.deg2rad(thT)),\n",
    "            ])\n",
    "\n",
    "        # â”€â”€ Exhaustive search â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        r = trace.iloc[idx]\n",
    "        xT, yT, zT = r[\"x_tx\"], r[\"y_tx\"], r[\"z_tx\"]\n",
    "        xR, yR, zR = r[\"x_rx\"], r[\"y_rx\"], r[\"z_rx\"]\n",
    "\n",
    "        bTx, bRx, _ = teacher.select(xT, yT, zT, xR, yR, zR)\n",
    "        sc_tx, sc_rx = teacher.beam_scores(xT, yT, zT, xR, yR, zR)\n",
    "        phT, thT, phR, thR = channel.angles(xT, yT, zT, xR, yR, zR)\n",
    "\n",
    "        seqs.append(window)\n",
    "        lTx.append(bTx);  lRx.append(bRx)\n",
    "        stx.append(sc_tx.astype(np.float32))\n",
    "        srx.append(sc_rx.astype(np.float32))\n",
    "        avecs.append(angles_to_unit_vector(phT, thT, phR, thR))\n",
    "\n",
    "        since_ckpt += 1\n",
    "        n_done = len(seqs)\n",
    "\n",
    "        if since_ckpt >= freq:\n",
    "            cache_mgr.save(name, seqs, lTx, lRx, stx, srx, avecs, partial_idx=idx)\n",
    "            elapsed = time.time() - t_start\n",
    "            rate    = n_done / elapsed\n",
    "            eta_min = (total - n_done) / rate / 60 if rate > 0 else 0\n",
    "            print(f\"  ðŸ’¾ {n_done}/{total} ({100*n_done/total:.1f}%)  \"\n",
    "                  f\"rate={rate:.2f}/s  ETA={eta_min:.1f} min\")\n",
    "            since_ckpt = 0\n",
    "        elif n_done % 50 == 0:\n",
    "            elapsed = time.time() - t_start\n",
    "            rate    = n_done / elapsed if elapsed > 0 else 0\n",
    "            eta_min = (total - n_done) / rate / 60 if rate > 0 else 0\n",
    "            print(f\"  ðŸ“Š {n_done}/{total} ({100*n_done/total:.1f}%)  \"\n",
    "                  f\"rate={rate:.2f}/s  ETA={eta_min:.1f} min\")\n",
    "\n",
    "    seqs    = np.array(seqs,    dtype=np.float32)\n",
    "    lTx     = np.array(lTx)\n",
    "    lRx     = np.array(lRx)\n",
    "    stx     = np.array(stx,    dtype=np.float32)\n",
    "    srx     = np.array(srx,    dtype=np.float32)\n",
    "    avecs   = np.array(avecs,  dtype=np.float32)\n",
    "\n",
    "    total_t = time.time() - t_start\n",
    "    print(f\"\\nâœ… Generated {len(seqs)} samples in {total_t/60:.1f} min\")\n",
    "    cache_mgr.save(name, seqs, lTx, lRx, stx, srx, avecs)\n",
    "    return seqs, lTx, lRx, stx, srx, avecs\n",
    "\n",
    "\n",
    "sequences, labels_Tx, labels_Rx, soft_tx, soft_rx, angle_vecs = \\\n",
    "    generate_training_data(mobility_trace, teacher, channel,\n",
    "                           config.SEQUENCE_LENGTH, pattern_name, cache_manager)\n",
    "\n",
    "print(f\"Dataset shape : {sequences.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70692644",
   "metadata": {},
   "source": [
    "## 8 Â· Model â€” Causal Transformer with RoPE & Beam Cross-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88576ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ RoPE utilities â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def rotate_half(x):\n",
    "    x1, x2 = x[..., :x.shape[-1]//2], x[..., x.shape[-1]//2:]\n",
    "    return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "class RotaryEmbedding(nn.Module):\n",
    "    def __init__(self, dim, base=10000):\n",
    "        super().__init__()\n",
    "        inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))\n",
    "        self.register_buffer(\"inv_freq\", inv_freq, persistent=False)\n",
    "\n",
    "    def forward(self, seq_len, device):\n",
    "        t     = torch.arange(seq_len, device=device).type_as(self.inv_freq)\n",
    "        freqs = torch.einsum(\"t,f->tf\", t, self.inv_freq)\n",
    "        emb   = torch.cat([freqs, freqs], dim=-1)\n",
    "        return emb.cos()[:, None, :], emb.sin()[:, None, :]\n",
    "\n",
    "def apply_rope(q, k, cos, sin):\n",
    "    return (q * cos) + (rotate_half(q) * sin), (k * cos) + (rotate_half(k) * sin)\n",
    "\n",
    "\n",
    "# â”€â”€ Attention block â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "class CausalRoPEAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, dropout=0.0):\n",
    "        super().__init__()\n",
    "        assert d_model % n_heads == 0\n",
    "        self.n_heads  = n_heads\n",
    "        self.head_dim = d_model // n_heads\n",
    "        self.q = nn.Linear(d_model, d_model)\n",
    "        self.k = nn.Linear(d_model, d_model)\n",
    "        self.v = nn.Linear(d_model, d_model)\n",
    "        self.o = nn.Linear(d_model, d_model)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.rope  = RotaryEmbedding(self.head_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, D = x.shape\n",
    "        H = self.n_heads\n",
    "        q = self.q(x).view(B, T, H, self.head_dim)\n",
    "        k = self.k(x).view(B, T, H, self.head_dim)\n",
    "        v = self.v(x).view(B, T, H, self.head_dim)\n",
    "        cos, sin = self.rope(T, x.device)\n",
    "        q, k = apply_rope(q, k, cos, sin)\n",
    "        att  = torch.einsum(\"bthd,bshd->bhts\", q, k) / math.sqrt(self.head_dim)\n",
    "        mask = torch.ones(T, T, device=x.device).tril()\n",
    "        att  = att.masked_fill(mask == 0, float(\"-inf\"))\n",
    "        att  = self.drop(torch.softmax(att, dim=-1))\n",
    "        out  = torch.einsum(\"bhts,bshd->bthd\", att, v).contiguous().view(B, T, D)\n",
    "        return self.o(out)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, dim_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.ln1  = nn.LayerNorm(d_model)\n",
    "        self.attn = CausalRoPEAttention(d_model, n_heads, dropout)\n",
    "        self.drop1= nn.Dropout(dropout)\n",
    "        self.ln2  = nn.LayerNorm(d_model)\n",
    "        self.ff   = nn.Sequential(\n",
    "            nn.Linear(d_model, dim_ff), nn.GELU(), nn.Dropout(dropout),\n",
    "            nn.Linear(dim_ff, d_model),\n",
    "        )\n",
    "        self.drop2= nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.drop1(self.attn(self.ln1(x)))\n",
    "        x = x + self.drop2(self.ff(self.ln2(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "# â”€â”€ Temporal encoder (Conv + Transformer) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "class TemporalEncoder(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        C = cfg.CONV_CHANNELS\n",
    "        K = cfg.CONV_KERNEL\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(cfg.STATE_FEATURE_DIM, C, K, stride=cfg.CONV_STRIDE, padding=K//2),\n",
    "            nn.GELU(),\n",
    "            nn.Conv1d(C, C, K, stride=cfg.CONV_STRIDE, padding=K//2),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "        self.proj   = nn.Linear(C, cfg.D_MODEL)\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlock(cfg.D_MODEL, cfg.N_HEADS, cfg.DIM_FEEDFORWARD, cfg.DROPOUT)\n",
    "            for _ in range(cfg.N_LAYERS)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):               # x: [B, T, F]\n",
    "        z = self.conv(x.transpose(1,2)).transpose(1,2)\n",
    "        z = self.proj(z)\n",
    "        for blk in self.blocks: z = blk(z)\n",
    "        return z\n",
    "\n",
    "\n",
    "# â”€â”€ Full model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "class CORTEXBeamSelector(nn.Module):\n",
    "    \"\"\"\n",
    "    CORTEX Stage II.\n",
    "    Input : [B, T, 17]\n",
    "    Output: tx_logits [B,255], rx_logits [B,255], angle_pred [B,6],\n",
    "            tx_conf [B,1], rx_conf [B,1]\n",
    "    \"\"\"\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        self.encoder = TemporalEncoder(cfg)\n",
    "\n",
    "        # Learnable beam codebooks\n",
    "        self.tx_codebook = nn.Parameter(torch.randn(cfg.NUM_TX_PATTERNS, cfg.BEAM_EMBED_DIM) * 0.02)\n",
    "        self.rx_codebook = nn.Parameter(torch.randn(cfg.NUM_RX_PATTERNS, cfg.BEAM_EMBED_DIM) * 0.02)\n",
    "\n",
    "        self.tx_kv = nn.Linear(cfg.BEAM_EMBED_DIM, cfg.D_MODEL)\n",
    "        self.rx_kv = nn.Linear(cfg.BEAM_EMBED_DIM, cfg.D_MODEL)\n",
    "\n",
    "        self.tx_cross = CausalRoPEAttention(cfg.D_MODEL, cfg.N_HEADS, cfg.DROPOUT)\n",
    "        self.rx_cross = CausalRoPEAttention(cfg.D_MODEL, cfg.N_HEADS, cfg.DROPOUT)\n",
    "        self.tx_res   = nn.Linear(cfg.D_MODEL, cfg.D_MODEL)\n",
    "        self.rx_res   = nn.Linear(cfg.D_MODEL, cfg.D_MODEL)\n",
    "\n",
    "        def _head(in_dim, out_dim):\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(in_dim, in_dim),   nn.LayerNorm(in_dim),   nn.GELU(), nn.Dropout(cfg.DROPOUT),\n",
    "                nn.Linear(in_dim, in_dim//2), nn.LayerNorm(in_dim//2), nn.GELU(), nn.Dropout(cfg.DROPOUT),\n",
    "                nn.Linear(in_dim//2, out_dim),\n",
    "            )\n",
    "\n",
    "        self.tx_cls  = _head(cfg.D_MODEL, cfg.NUM_TX_PATTERNS)\n",
    "        self.rx_cls  = _head(cfg.D_MODEL, cfg.NUM_RX_PATTERNS)\n",
    "\n",
    "        self.tx_conf = nn.Sequential(nn.Linear(cfg.D_MODEL, cfg.D_MODEL//4),\n",
    "                                     nn.ReLU(), nn.Linear(cfg.D_MODEL//4, 1), nn.Sigmoid())\n",
    "        self.rx_conf = nn.Sequential(nn.Linear(cfg.D_MODEL, cfg.D_MODEL//4),\n",
    "                                     nn.ReLU(), nn.Linear(cfg.D_MODEL//4, 1), nn.Sigmoid())\n",
    "\n",
    "        if cfg.USE_ANGLE_REFINEMENT:\n",
    "            self.angle_refiner = nn.Sequential(\n",
    "                nn.Linear(cfg.D_MODEL*2, cfg.D_MODEL), nn.LayerNorm(cfg.D_MODEL),\n",
    "                nn.GELU(), nn.Dropout(cfg.DROPOUT),\n",
    "                nn.Linear(cfg.D_MODEL, cfg.D_MODEL//2), nn.LayerNorm(cfg.D_MODEL//2),\n",
    "                nn.GELU(), nn.Linear(cfg.D_MODEL//2, 6),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B  = x.size(0)\n",
    "        enc= self.encoder(x)                                    # [B, T', D]\n",
    "        q  = enc[:, -1:, :] + 0.5 * enc.mean(dim=1, keepdim=True)  # [B,1,D]\n",
    "\n",
    "        def _cross(query, codebook_proj, cross_attn, residual_proj):\n",
    "            kv  = codebook_proj.unsqueeze(0).expand(B, -1, -1)  # [B, num_beams, D]\n",
    "            seq = torch.cat([query, kv], dim=1)\n",
    "            out = cross_attn(seq)[:, 0, :]                      # [B, D]\n",
    "            return query.squeeze(1) + residual_proj(out)\n",
    "\n",
    "        tx_out = _cross(q, self.tx_kv(self.tx_codebook), self.tx_cross, self.tx_res)\n",
    "        rx_out = _cross(q, self.rx_kv(self.rx_codebook), self.rx_cross, self.rx_res)\n",
    "\n",
    "        tx_logits = self.tx_cls(tx_out)\n",
    "        rx_logits = self.rx_cls(rx_out)\n",
    "        tx_conf   = self.tx_conf(tx_out)\n",
    "        rx_conf   = self.rx_conf(rx_out)\n",
    "\n",
    "        angles = None\n",
    "        if self.cfg.USE_ANGLE_REFINEMENT:\n",
    "            angles = self.angle_refiner(torch.cat([tx_out, rx_out], dim=1))\n",
    "        return tx_logits, rx_logits, angles, tx_conf, rx_conf\n",
    "\n",
    "\n",
    "model = CORTEXBeamSelector(config).to(device)\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Parameters: {n_params:,}  ({n_params*4/1024/1024:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bd94ae",
   "metadata": {},
   "source": [
    "## 9 Â· Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed8e6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal loss â€” down-weights easy examples to focus training on hard ones.\"\"\"\n",
    "    def __init__(self, gamma=2.0, label_smoothing=0.0):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.ce = nn.CrossEntropyLoss(label_smoothing=label_smoothing, reduction=\"none\")\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        ce   = self.ce(logits, targets)\n",
    "        pt   = torch.exp(-ce)\n",
    "        return ((1 - pt) ** self.gamma * ce).mean()\n",
    "\n",
    "\n",
    "def distillation_loss(student_logits, soft_targets, temperature):\n",
    "    \"\"\"KL-divergence KD loss (temperature-scaled).\"\"\"\n",
    "    log_p = torch.log_softmax(student_logits / temperature, dim=1)\n",
    "    q     = torch.softmax(soft_targets / temperature, dim=1)\n",
    "    return nn.KLDivLoss(reduction=\"batchmean\")(log_p, q) * (temperature ** 2)\n",
    "\n",
    "\n",
    "class WrappedCauchyLoss(nn.Module):\n",
    "    \"\"\"Circular-aware loss for 6-D unit vectors (TX + RX angle refinement).\"\"\"\n",
    "    def __init__(self, rho=0.9, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.rho, self.eps = rho, eps\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        def norm(v): return v / (v.norm(dim=1, keepdim=True) + self.eps)\n",
    "        ptx, prx = norm(pred[:,  :3]), norm(pred[:,  3:])\n",
    "        ttx, trx = norm(target[:,:3]), norm(target[:,3:])\n",
    "        cos_tx = (ptx * ttx).sum(1).clamp(-1+self.eps, 1-self.eps)\n",
    "        cos_rx = (prx * trx).sum(1).clamp(-1+self.eps, 1-self.eps)\n",
    "        rho2   = self.rho**2\n",
    "        return (torch.log(1 + rho2 - 2*self.rho*cos_tx + self.eps) +\n",
    "                torch.log(1 + rho2 - 2*self.rho*cos_rx + self.eps)).mean()\n",
    "\n",
    "\n",
    "focal_loss  = FocalLoss(gamma=config.FOCAL_GAMMA, label_smoothing=config.LABEL_SMOOTHING)\n",
    "angle_loss  = WrappedCauchyLoss(rho=config.WC_RHO)\n",
    "print(\"Loss functions ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0fef3c",
   "metadata": {},
   "source": [
    "## 10 Â· Dataset & DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2896ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamDataset(Dataset):\n",
    "    def __init__(self, seqs, lTx, lRx, stx, srx, avecs):\n",
    "        self.seqs  = torch.FloatTensor(seqs)\n",
    "        self.lTx   = torch.LongTensor(lTx)\n",
    "        self.lRx   = torch.LongTensor(lRx)\n",
    "        self.stx   = torch.FloatTensor(stx)\n",
    "        self.srx   = torch.FloatTensor(srx)\n",
    "        self.avecs = torch.FloatTensor(avecs)\n",
    "\n",
    "    def __len__(self): return len(self.seqs)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.seqs[i], self.lTx[i], self.lRx[i], self.stx[i], self.srx[i], self.avecs[i]\n",
    "\n",
    "\n",
    "(tr_s, va_s, tr_Tx, va_Tx, tr_Rx, va_Rx,\n",
    " tr_stx, va_stx, tr_srx, va_srx, tr_av, va_av) = train_test_split(\n",
    "    sequences, labels_Tx, labels_Rx, soft_tx, soft_rx, angle_vecs,\n",
    "    test_size=1-config.TRAIN_SPLIT, random_state=SEED\n",
    ")\n",
    "\n",
    "train_ds = BeamDataset(tr_s,  tr_Tx, tr_Rx,  tr_stx,  tr_srx,  tr_av)\n",
    "val_ds   = BeamDataset(va_s,  va_Tx, va_Rx,  va_stx,  va_srx,  va_av)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=config.BATCH_SIZE, shuffle=True,  num_workers=2, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=config.BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "print(f\"Train: {len(train_ds):,}  |  Val: {len(val_ds):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99f3797",
   "metadata": {},
   "source": [
    "## 11 Â· Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e82e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_schedule(start, end, step, total):\n",
    "    return start + (end - start) * min(max(step, 0), total) / max(total, 1)\n",
    "\n",
    "def topk_masked(logits, k):\n",
    "    \"\"\"Zero out all but the top-K values (for sparse KD targets).\"\"\"\n",
    "    if k <= 0 or k >= logits.size(1): return logits\n",
    "    _, idx = torch.topk(logits, k, dim=1)\n",
    "    return torch.zeros_like(logits).scatter_(1, idx, logits.gather(1, idx))\n",
    "\n",
    "\n",
    "def run_epoch(model, loader, optimizer, training, epoch):\n",
    "    model.train() if training else model.eval()\n",
    "    total_loss = 0\n",
    "    correct_tx = correct_rx = correct_both = n = 0\n",
    "\n",
    "    T     = lin_schedule(config.DISTILL_TEMPERATURE_MAX, config.DISTILL_TEMPERATURE_MIN,\n",
    "                         epoch, config.NUM_EPOCHS - 1)\n",
    "    alpha = lin_schedule(config.DISTILL_ALPHA_MIN, config.DISTILL_ALPHA_MAX,\n",
    "                         epoch, config.NUM_EPOCHS - 1)\n",
    "\n",
    "    ctx = torch.enable_grad() if training else torch.no_grad()\n",
    "    with ctx:\n",
    "        for seq, yTx, yRx, stx, srx, avec in loader:\n",
    "            seq  = seq.to(device);  yTx  = yTx.to(device); yRx = yRx.to(device)\n",
    "            stx  = stx.to(device);  srx  = srx.to(device); avec= avec.to(device)\n",
    "\n",
    "            tx_log, rx_log, ang, _, _ = model(seq)\n",
    "\n",
    "            l_tx_hard = focal_loss(tx_log, yTx)\n",
    "            l_rx_hard = focal_loss(rx_log, yRx)\n",
    "\n",
    "            if training and config.USE_DISTILLATION:\n",
    "                l_tx = alpha * l_tx_hard + (1-alpha) * distillation_loss(tx_log, topk_masked(stx, config.TOPK_TX), T)\n",
    "                l_rx = alpha * l_rx_hard + (1-alpha) * distillation_loss(rx_log, topk_masked(srx, config.TOPK_RX), T)\n",
    "            else:\n",
    "                l_tx, l_rx = l_tx_hard, l_rx_hard\n",
    "\n",
    "            loss = l_tx + l_rx\n",
    "            if config.USE_ANGLE_REFINEMENT and ang is not None:\n",
    "                loss = loss + config.ANGLE_LOSS_WEIGHT * angle_loss(ang, avec)\n",
    "\n",
    "            if training:\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "            total_loss   += loss.item()\n",
    "            pred_tx       = tx_log.argmax(1);  pred_rx = rx_log.argmax(1)\n",
    "            correct_tx   += (pred_tx == yTx).sum().item()\n",
    "            correct_rx   += (pred_rx == yRx).sum().item()\n",
    "            correct_both += ((pred_tx == yTx) & (pred_rx == yRx)).sum().item()\n",
    "            n            += yTx.size(0)\n",
    "\n",
    "    return total_loss/len(loader), correct_tx/n, correct_rx/n, correct_both/n\n",
    "\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=config.LEARNING_RATE, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=50, T_mult=2, eta_min=1e-7)\n",
    "\n",
    "# â”€â”€ Resume from checkpoint if available â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "start_epoch = 0\n",
    "best_val_acc = 0.0\n",
    "\n",
    "prev_ckpt = ckpt_manager.load_latest()\n",
    "if prev_ckpt is not None:\n",
    "    model.load_state_dict(prev_ckpt[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(prev_ckpt[\"optimizer_state_dict\"])\n",
    "    scheduler.load_state_dict(prev_ckpt[\"scheduler_state_dict\"])\n",
    "    start_epoch  = prev_ckpt[\"epoch\"] + 1\n",
    "    best_val_acc = prev_ckpt[\"metrics\"][\"best_val_acc\"]\n",
    "    print(f\"ðŸ”„ Resumed from epoch {start_epoch}  (best val: {best_val_acc*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"Starting fresh training.\")\n",
    "\n",
    "print(f\"Training for {config.NUM_EPOCHS - start_epoch} more epochsâ€¦\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1414a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join(LOGS_DIR, f\"log_{pattern_name[:80]}.csv\")\n",
    "if start_epoch == 0:\n",
    "    with open(log_path, \"w\") as f:\n",
    "        f.write(\"epoch,train_loss,val_loss,train_both,val_both,lr,time\\n\")\n",
    "\n",
    "for epoch in range(start_epoch, config.NUM_EPOCHS):\n",
    "    t0 = time.time()\n",
    "    tr_loss, tr_tx, tr_rx, tr_both = run_epoch(model, train_loader, optimizer, True,  epoch)\n",
    "    va_loss, va_tx, va_rx, va_both = run_epoch(model, val_loader,   optimizer, False, epoch)\n",
    "    scheduler.step()\n",
    "\n",
    "    lr      = optimizer.param_groups[0][\"lr\"]\n",
    "    elapsed = time.time() - t0\n",
    "    is_best = va_both > best_val_acc\n",
    "    if is_best: best_val_acc = va_both\n",
    "\n",
    "    with open(log_path, \"a\") as f:\n",
    "        f.write(f\"{epoch},{tr_loss:.6f},{va_loss:.6f},{tr_both:.6f},{va_both:.6f},{lr:.8f},{elapsed:.1f}\\n\")\n",
    "\n",
    "    save_now = is_best or (epoch+1) % config.CHECKPOINT_EVERY_N_EPOCHS == 0 or epoch == config.NUM_EPOCHS-1\n",
    "    if save_now:\n",
    "        ckpt_manager.save(epoch, model, optimizer, scheduler,\n",
    "                         {\"train_loss\": tr_loss, \"val_loss\": va_loss,\n",
    "                          \"train_both_acc\": tr_both, \"val_both_acc\": va_both,\n",
    "                          \"best_val_acc\": best_val_acc},\n",
    "                         is_best=is_best)\n",
    "\n",
    "    if epoch % 20 == 0 or epoch == config.NUM_EPOCHS - 1:\n",
    "        print(f\"Epoch {epoch:3d}: \"\n",
    "              f\"TrLoss={tr_loss:.4f}  ValLoss={va_loss:.4f}  \"\n",
    "              f\"Tx={va_tx*100:.1f}%  Rx={va_rx*100:.1f}%  Both={va_both*100:.1f}% \"\n",
    "              f\"{'ðŸŒŸ' if is_best else '  '}  LR={lr:.1e}  {elapsed:.1f}s\")\n",
    "\n",
    "print(f\"\\nâœ… Training complete. Best joint acc: {best_val_acc*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f850234",
   "metadata": {},
   "source": [
    "## 12 Â· Evaluation â€” Spectral Efficiency vs. Exhaustive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdae094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best checkpoint\n",
    "best_ckpt = ckpt_manager.load_best()\n",
    "if best_ckpt:\n",
    "    model.load_state_dict(best_ckpt[\"model_state_dict\"])\n",
    "    print(f\"Best model loaded (epoch {best_ckpt['epoch']}, \"\n",
    "          f\"val acc {best_ckpt['metrics']['best_val_acc']*100:.1f}%)\")\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def evaluate_spectral_efficiency(model, trace, teacher, channel, cfg,\n",
    "                                 name, results_dir):\n",
    "    \"\"\"\n",
    "    Compare CORTEX vs. exhaustive search on every timestep.\n",
    "    Saves incremental CSV checkpoints every 100 steps.\n",
    "    Returns a DataFrame with capacity columns.\n",
    "    \"\"\"\n",
    "    safe      = name.replace(\"/\",\"_\").replace(\" \",\"_\")[:80]\n",
    "    ckpt_csv  = os.path.join(results_dir, f\"eval_ckpt_{safe}.csv\")\n",
    "    final_csv = os.path.join(results_dir, f\"results_{safe}.csv\")\n",
    "\n",
    "    # Resume if an eval checkpoint exists\n",
    "    rows, start = [], cfg.SEQUENCE_LENGTH - 1\n",
    "    if os.path.exists(ckpt_csv):\n",
    "        df_prev = pd.read_csv(ckpt_csv)\n",
    "        rows    = df_prev.to_dict(\"records\")\n",
    "        start   = len(rows) + cfg.SEQUENCE_LENGTH - 1\n",
    "        print(f\"ðŸ”„ Resuming eval from step {start} ({len(rows)} done)\")\n",
    "\n",
    "    for idx in range(start, len(trace)):\n",
    "        window = []\n",
    "        for t in range(idx - cfg.SEQUENCE_LENGTH + 1, idx + 1):\n",
    "            r = trace.iloc[t]\n",
    "            xT,yT,zT = r[\"x_tx\"],r[\"y_tx\"],r[\"z_tx\"]\n",
    "            xR,yR,zR = r[\"x_rx\"],r[\"y_rx\"],r[\"z_rx\"]\n",
    "            d = channel.distance(xT,yT,zT,xR,yR,zR)\n",
    "            phT,thT,_,_ = channel.angles(xT,yT,zT,xR,yR,zR)\n",
    "            window.append([\n",
    "                xT/100,yT/100,zT/100,xR/100,yR/100,zR/100,d/100,\n",
    "                r[\"vx_tx\"]/10,r[\"vy_tx\"]/10,r[\"vz_tx\"]/10,\n",
    "                r[\"vx_rx\"]/10,r[\"vy_rx\"]/10,r[\"vz_rx\"]/10,\n",
    "                np.sin(np.deg2rad(phT)),np.cos(np.deg2rad(phT)),\n",
    "                np.sin(np.deg2rad(thT)),np.cos(np.deg2rad(thT)),\n",
    "            ])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            t_in = torch.FloatTensor([window]).to(device)\n",
    "            tx_log, rx_log, _, _, _ = model(t_in)\n",
    "            tx_pred = tx_log.argmax(1).item()\n",
    "            rx_pred = rx_log.argmax(1).item()\n",
    "\n",
    "        r   = trace.iloc[idx]\n",
    "        xT,yT,zT = r[\"x_tx\"],r[\"y_tx\"],r[\"z_tx\"]\n",
    "        xR,yR,zR = r[\"x_rx\"],r[\"y_rx\"],r[\"z_rx\"]\n",
    "        phT,thT,phR,thR = channel.angles(xT,yT,zT,xR,yR,zR)\n",
    "        d   = channel.distance(xT,yT,zT,xR,yR,zR)\n",
    "        cg, tau = channel.channel_gain(d)\n",
    "        Pn  = channel.noise(tau)\n",
    "\n",
    "        GTx  = teacher.gain(tx_pred, phT, thT)\n",
    "        GRx  = teacher.gain(rx_pred, phR, thR)\n",
    "        cap, _  = channel.capacity(GTx, GRx, cg, Pn)\n",
    "        _,_,opt = teacher.select(xT,yT,zT,xR,yR,zR)\n",
    "\n",
    "        rows.append({\n",
    "            \"time\":         r[\"time\"],\n",
    "            \"capacity\":     cap / 1e9,\n",
    "            \"opt_capacity\": opt / 1e9,\n",
    "            \"tx_beam\":      tx_pred,\n",
    "            \"rx_beam\":      rx_pred,\n",
    "        })\n",
    "\n",
    "        done = idx + 1 - (cfg.SEQUENCE_LENGTH - 1)\n",
    "        if done % 100 == 0:\n",
    "            pd.DataFrame(rows).to_csv(ckpt_csv, index=False)\n",
    "            total = len(trace) - (cfg.SEQUENCE_LENGTH - 1)\n",
    "            print(f\"  ðŸ’¾ {done}/{total} ({100*done/total:.1f}%)\")\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(final_csv, index=False)\n",
    "    if os.path.exists(ckpt_csv): os.remove(ckpt_csv)\n",
    "    print(f\"âœ… Evaluation saved: {final_csv}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "results = evaluate_spectral_efficiency(\n",
    "    model, mobility_trace, teacher, channel,\n",
    "    config, pattern_name, RESULTS_DIR\n",
    ")\n",
    "\n",
    "avg_cap  = results[\"capacity\"].mean()\n",
    "avg_opt  = results[\"opt_capacity\"].mean()\n",
    "eff      = avg_cap / avg_opt\n",
    "print(f\"\\nCORTEX     : {avg_cap:.4f} Gbps\")\n",
    "print(f\"Exhaustive : {avg_opt:.4f} Gbps\")\n",
    "print(f\"Efficiency : {eff*100:.1f}%\")\n",
    "print(f\"Gap        : {(1-eff)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74280688",
   "metadata": {},
   "source": [
    "## 13 Â· IEEE Paper Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f7c018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PLOTS_DIR = os.path.join(EXPERIMENT_ROOT, \"paper_plots\")\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.family\":      \"serif\",\n",
    "    \"font.serif\":       [\"Times New Roman\"],\n",
    "    \"font.size\":        10,\n",
    "    \"axes.labelsize\":   10,\n",
    "    \"axes.titlesize\":   10,\n",
    "    \"legend.fontsize\":   9,\n",
    "    \"xtick.labelsize\":   9,\n",
    "    \"ytick.labelsize\":   9,\n",
    "    \"lines.linewidth\":  1.5,\n",
    "    \"lines.markersize\":  4,\n",
    "    \"grid.alpha\":       0.3,\n",
    "})\n",
    "\n",
    "def save_fig(name):\n",
    "    for ext in (\"png\", \"pdf\"):\n",
    "        plt.savefig(os.path.join(PLOTS_DIR, f\"{name}.{ext}\"),\n",
    "                    dpi=300, bbox_inches=\"tight\", format=ext)\n",
    "    print(f\"  Saved: {name}.png / .pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d73f0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ (a) Training dynamics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df_log = pd.read_csv(log_path)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7.16, 3.0))\n",
    "\n",
    "ax1.plot(df_log[\"epoch\"], df_log[\"train_loss\"], label=\"Train\")\n",
    "ax1.plot(df_log[\"epoch\"], df_log[\"val_loss\"],   label=\"Validation\", linestyle=\"--\")\n",
    "ax1.set(xlabel=\"Epoch\", ylabel=\"Loss\", title=\"(a) Training Convergence\")\n",
    "ax1.legend(); ax1.grid()\n",
    "\n",
    "ax2.plot(df_log[\"epoch\"], df_log[\"train_both\"]*100, label=\"Train (Joint)\")\n",
    "ax2.plot(df_log[\"epoch\"], df_log[\"val_both\"]  *100, label=\"Val (Joint)\", linestyle=\"--\")\n",
    "ax2.set(xlabel=\"Epoch\", ylabel=\"Accuracy (%)\", title=\"(b) Joint Beam Accuracy\")\n",
    "ax2.legend(); ax2.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "save_fig(\"fig_training_dynamics\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0713ad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ (b) Spectral efficiency CDF â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "BW_GHZ = config.BANDWIDTH / 1e9\n",
    "se_pred = results[\"capacity\"]     / BW_GHZ\n",
    "se_opt  = results[\"opt_capacity\"] / BW_GHZ\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3.5, 3.0))\n",
    "\n",
    "for vals, label, color, ls in [\n",
    "    (se_opt,  \"Optimal (Exhaustive)\", \"k\",       \"--\"),\n",
    "    (se_pred, \"Proposed CORTEX\",      \"#d62728\",  \"-\"),\n",
    "]:\n",
    "    x = np.sort(vals)\n",
    "    y = np.arange(1, len(x)+1) / len(x)\n",
    "    ax.plot(x, y, color=color, linestyle=ls, label=label)\n",
    "\n",
    "med_ratio = np.median(se_pred) / np.median(se_opt)\n",
    "ax.text(0.05, 0.55,\n",
    "        f\"Median efficiency:\\n{med_ratio*100:.1f}%\",\n",
    "        transform=ax.transAxes,\n",
    "        bbox=dict(facecolor=\"white\", alpha=0.8, edgecolor=\"none\"))\n",
    "\n",
    "ax.set(xlabel=\"Spectral Efficiency (bps/Hz)\", ylabel=\"CDF\", xlim=(0, None), ylim=(0, 1.05))\n",
    "ax.legend(loc=\"lower right\"); ax.grid()\n",
    "plt.tight_layout()\n",
    "save_fig(\"fig_cdf_spectral_efficiency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a322400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ (c) Capacity time-series â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "subset = results.iloc[:min(200, len(results))]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7.16, 3.0))\n",
    "ax.plot(subset[\"time\"], subset[\"opt_capacity\"], color=\"k\",       alpha=0.4, lw=1,   label=\"Optimal\")\n",
    "ax.plot(subset[\"time\"], subset[\"capacity\"],     color=\"#1f77b4\", lw=1.5,           label=\"CORTEX\")\n",
    "ax.set(xlabel=\"Time (s)\", ylabel=\"Capacity (Gbps)\",\n",
    "       xlim=(subset[\"time\"].iloc[0], subset[\"time\"].iloc[-1]))\n",
    "ax.legend(ncol=2); ax.grid()\n",
    "plt.tight_layout()\n",
    "save_fig(\"fig_rate_tracking\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAll plots saved to: {PLOTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319b6d38",
   "metadata": {},
   "source": [
    "## Citation\n",
    "\n",
    "```bibtex\n",
    "@article{usta2026cortex,\n",
    "  author  = {Usta, Mahir Burak and Bafarassat, Milad and Erdem, Mikail and\n",
    "             Gurbuz, Ozgur and Saeed, Akhtar and Tokgoz, Korkut Kaan and Qaraqe, Khalid},\n",
    "  title   = {Transformer-Driven Beam Control via Reconfigurable Antenna Arrays\n",
    "             for Terahertz {UAV} Communications},\n",
    "  journal = {IEEE Open Journal of the Communications Society},\n",
    "  year    = {2026},\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
